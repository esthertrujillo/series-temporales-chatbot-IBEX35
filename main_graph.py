import os
import re
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv
from typing import Optional, List, Dict, Any
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, END
from langchain_core.runnables import RunnableLambda
from langchain_groq import ChatGroq

from qdrant_utils import buscar_en_qdrant 
from prompts import PROMPT_SERIES, PROMPT_API_EXTRAER, PROMPT_CLASIFICACION, PROMPT_RAG_DOCUMENTOS
from cotizaciones import construir_respuesta_yfinance # Esta funciÃ³n deberÃ­a devolver una respuesta estructurada o el precio
from series_model import ejecutar_prediccion 

# ---------------------------------------------------------
# 1. ConfiguraciÃ³n del modelo
# ---------------------------------------------------------

load_dotenv()
print("GROQ_API_KEY cargada:", os.getenv("GROQ_API_KEY"))

llm = ChatGroq(
    groq_api_key=os.getenv("GROQ_API_KEY"),
    model_name="llama3-8b-8192", 
    temperature=0.1
)

# ---------------------------------------------------------
# 2. Estado del chatbot 
# ---------------------------------------------------------

class ChatbotState(TypedDict):
    input: str 
    empresa: Optional[str]
    tipo_pregunta: Optional[str]
    respuesta: Optional[str]
    fuente: Optional[str]
    fecha_inicio: Optional[str]
    fecha_fin: Optional[str]
    grafico_base64: Optional[str] 
    historial_preguntas: Optional[List[str]] 
    historial_completo: Optional[List[Dict[str, Any]]] 
    pregunta_completa: Optional[str] 
    fecha_actual: Optional[str] 
    datos_recopilados: Optional[Dict[str, Any]] # Para almacenar datos para la comparaciÃ³n
    # NUEVO: Campo para guardar datos estructurados por empresa
    datos_empresa_cache: Optional[Dict[str, Dict[str, Any]]] 


# ---------------------------------------------------------
# 3. Funciones auxiliares
# ---------------------------------------------------------


def extract_json(text):
    """
    Attempts to extract a JSON object from a given text string.
    It first looks for a JSON block enclosed in ```json...```.
    If not found, it tries to find a standalone JSON object {}.
    """
    print(f"[DEBUG - extract_json] Attempting to extract JSON from text:\n{text[:500]}...") # Print first 500 chars

    # 1. Try to find a JSON block enclosed in ```json and ```
    # re.DOTALL allows '.' to match newlines
    match_code_block = re.search(r'```json\s*(\{.*\})\s*```', text, re.DOTALL)
    if match_code_block:
        try:
            json_str = match_code_block.group(1)
            print(f"[DEBUG - extract_json] Found JSON in code block. Attempting to decode: {json_str[:200]}...")
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"[ERROR - extract_json] Decoding JSON from code block failed: {e}")
            print(f"[ERROR - extract_json] Problematic text: {json_str}")
            # Fall through to try standalone match if code block failed to decode

    match_standalone = re.search(r'(\{.*?\})', text, re.DOTALL) 
    if match_standalone:
        try:
            json_str = match_standalone.group(1)
            print(f"[DEBUG - extract_json] Found standalone JSON. Attempting to decode: {json_str[:200]}...")
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"[ERROR - extract_json] Decoding standalone JSON failed: {e}")
            print(f"[ERROR - extract_json] Problematic text: {json_str}")
            return None # If standalone fails, there's likely no valid JSON
    
    print("[ERROR - extract_json] No valid JSON block found in the text.")
    return None # No JSON block found at all


def normalizar_fechas_relativas(fecha_inicio: Optional[str], fecha_fin: Optional[str]) -> tuple[Optional[str], Optional[str]]:
    hoy_dt = datetime.today()

    def get_last_monday(date_ref):
        return date_ref - timedelta(days=date_ref.weekday() + 7) 

    def to_str(date_obj):
        return date_obj.strftime("%Y-%m-%d")

    if fecha_inicio:
        fecha_inicio_lower = fecha_inicio.lower()
        if "lunes pasado" in fecha_inicio_lower:
            fecha_inicio = to_str(get_last_monday(hoy_dt))
        elif "hoy" in fecha_inicio_lower:
            fecha_inicio = to_str(hoy_dt)
        elif "ayer" in fecha_inicio_lower:
            fecha_inicio = to_str(hoy_dt - timedelta(days=1))
    
    if fecha_fin:
        fecha_fin_lower = fecha_fin.lower()
        if "lunes pasado" in fecha_fin_lower: 
            fecha_fin = to_str(get_last_monday(hoy_dt) + timedelta(days=4)) 
        elif "hoy" in fecha_fin_lower:
            fecha_fin = to_str(hoy_dt)
        elif "ayer" in fecha_fin_lower:
            fecha_fin = to_str(hoy_dt - timedelta(days=1))

    if fecha_inicio and not re.match(r"\d{4}-\d{2}-\d{2}", fecha_inicio):
        try:
            parsed_date = datetime.strptime(fecha_inicio + f"-{hoy_dt.year}", "%m-%d-%Y")
            fecha_inicio = to_str(parsed_date)
        except ValueError:
            try: 
                parsed_date = datetime.strptime(fecha_inicio, "%Y-%m-%d")
                fecha_inicio = to_str(parsed_date)
            except ValueError:
                pass 

    if fecha_fin and not re.match(r"\d{4}-\d{2}-\d{2}", fecha_fin):
        try:
            parsed_date = datetime.strptime(fecha_fin + f"-{hoy_dt.year}", "%m-%d-%Y")
            fecha_fin = to_str(parsed_date)
        except ValueError:
            try:
                parsed_date = datetime.strptime(fecha_fin, "%Y-%m-%d")
                fecha_fin = to_str(parsed_date)
            except ValueError:
                pass 

    return fecha_inicio, fecha_fin


# ---------------------------------------------------------
# 4. Nodo: ClasificaciÃ³n
# ---------------------------------------------------------

def clasificar_intencion(state: ChatbotState) -> ChatbotState:
    pregunta_original = state["input"]
    historial_preguntas_previas = state.get("historial_preguntas", [])
    historial_para_prompt = "\n".join(historial_preguntas_previas) if historial_preguntas_previas else "No hay historial previo."
    fecha_actual = state.get("fecha_actual", datetime.now().strftime("%Y-%m-%d"))

    prompt = PROMPT_CLASIFICACION.format(
        pregunta_original=pregunta_original,
        historial_conversacion=historial_para_prompt,
        fecha_actual=fecha_actual # Pasamos la fecha actual
    )

    respuesta_llm = llm.invoke(prompt).content.strip()

    tipo = "consulta_api" 
    pregunta_completa = pregunta_original 
    justificacion = "No se pudo obtener una justificaciÃ³n." 

    try:
        data = extract_json(respuesta_llm)
        tipo = data.get("clasificacion", "consulta_api").lower()
        pregunta_completa = data.get("pregunta_completa", pregunta_original)
        justificacion = data.get("justificacion", "No se encontrÃ³ justificaciÃ³n en la respuesta del LLM.")
        
        # Eliminada 'comparacion_financiera' de categorÃ­as vÃ¡lidas
        categorias_validas = {"series_temporales", "documentos_financieros", "consulta_api"}
        if tipo not in categorias_validas:
            print(f"âš ï¸ Tipo de pregunta '{tipo}' no vÃ¡lido. Usando 'consulta_api' como fallback.")
            tipo = "consulta_api"

    except ValueError as e:
        print(f"âŒ Error al extraer JSON de clasificaciÃ³n/pregunta_completa/justificacion: {e}\nRespuesta RAW del LLM:\n{respuesta_llm}")
        justificacion = f"Error al parsear la respuesta del LLM: {e}"


    print(f"\n--- [ğŸ” CLASIFICADOR] DEBUGGING INFO ---") 
    print(f"[ğŸ” CLASIFICADOR] Prompt enviado al LLM:\n{prompt}") 
    print(f"[ğŸ” CLASIFICADOR] Respuesta RAW del LLM:\n{respuesta_llm}")
    print(f"[ğŸ” CLASIFICADOR] Pregunta original: {pregunta_original}")
    print(f"[ğŸ” CLASIFICADOR] Pregunta completa generada: {pregunta_completa}")
    print(f"[ğŸ” CLASIFICADOR] Tipo detectado: {tipo}")
    print(f"[ğŸ” CLASIFICADOR] JustificaciÃ³n: {justificacion}")
    print(f"--- [ğŸ” CLASIFICADOR] FIN DEBUGGING INFO ---\n")

    historial_preguntas_actualizado = historial_preguntas_previas + [pregunta_original]
    historial_preguntas_actualizado = historial_preguntas_actualizado[-3:]

    return {
        **state,
        "tipo_pregunta": tipo,
        "pregunta_completa": pregunta_completa,
        "historial_preguntas": historial_preguntas_actualizado,
        "fuente": "clasificador"
    }

# ---------------------------------------------------------
# 5. Nodo de decisiÃ³n
# ---------------------------------------------------------

def seleccionar_fuente(state: ChatbotState) -> str:
    return state["tipo_pregunta"]

# ---------------------------------------------------------
# 6. Nodo: Series temporales
# ---------------------------------------------------------

def analizar_series_temporales(state: ChatbotState) -> ChatbotState:
    pregunta_original = state["input"]
    pregunta_completa = state["pregunta_completa"]
    fecha_actual = state.get("fecha_actual", datetime.now().strftime("%Y-%m-%d"))
    print(f"[ğŸ“Š SERIES] Analizando series temporales con:\n Â  Original: '{pregunta_original}'\n Â  Completa: '{pregunta_completa}'\n Â  Fecha Actual: '{fecha_actual}'")

    prompt = PROMPT_SERIES.format(
        pregunta_original=pregunta_original,
        pregunta_completa=pregunta_completa,
        fecha_actual=fecha_actual
    )
    response = llm.invoke(prompt)
    try:
        data = extract_json(response.content)
    except Exception as e:
        print(f"âš ï¸ Error extrayendo JSON del LLM en nodo Series Temporales: {e}")
        return {
            **state,
            "respuesta": "âŒ No se pudo extraer la informaciÃ³n necesaria para la predicciÃ³n de series temporales.",
            "fuente": "series_temporales",
            "grafico_base64": None # Ensure it's None on error
        }

    empresa = data.get("empresa", "BBVA").upper()
    lag = int(data.get("lag", 1))
    respuesta_simulada = data.get("respuesta", "")

    print(f"[ğŸ“Š SERIES] Empresa detectada: {empresa}, lag: {lag}")
    print(f"[ğŸ“Š SERIES] Respuesta simulada (del LLM): {respuesta_simulada}")

    modelos_dir = os.path.join(os.getcwd(), "modelos_por_empresa")
    path_csv = os.path.join(os.getcwd(), "data/IBEX35_cotizaciones_20_Limpio.csv")

    resultado = ejecutar_prediccion(empresa, lag, path_csv, modelos_dir)
    respuesta_real_modelo = resultado.get("respuesta", "No se pudo obtener la predicciÃ³n real.")
    grafico_base64 = resultado.get("grafico_base64", None) # <--- GET THE BASE64 STRING HERE

    final_respuesta = respuesta_real_modelo if "No se pudo obtener" not in respuesta_real_modelo else respuesta_simulada

    return {
        **state,
        "respuesta": final_respuesta,
        "fuente": "series_temporales",
        "empresa": empresa,
        "grafico_base64": grafico_base64 # <--- ADD IT TO THE STATE HERE
    }

# ---------------------------------------------------------
# 7. Nodo: Documentos financieros -> Qdrant - Â¡ACTUALIZADO!
# ---------------------------------------------------------

def consulta_qdrant(state: ChatbotState) -> ChatbotState:
    pregunta_original = state["input"]
    pregunta_completa = state["pregunta_completa"] 
    fecha_actual = state.get("fecha_actual", datetime.now().strftime("%Y-%m-%d")) 
    print(f"\n[ğŸ“š Nodo RAG] âœ… Entrada al nodo 'consulta_qdrant' con:\n   Original: '{pregunta_original}'\n   Completa: '{pregunta_completa}'\n   Fecha Actual: '{fecha_actual}'")

    # Inicializar o recuperar datos_empresa_cache
    datos_empresa_cache = state.get("datos_empresa_cache", {})
    
    try:
        print("[ğŸ“š Nodo RAG] Buscando fragmentos en Qdrant...")
        resultados = buscar_en_qdrant(pregunta_completa) 

        fragmentos = [r.payload.get("resumen", "") for r in resultados if hasattr(r, 'payload') and r.payload and r.payload.get("resumen")]
        
        if not fragmentos:
            print("[ğŸ“š Nodo RAG] âš ï¸ No se encontraron fragmentos relevantes en Qdrant.")
            return {
                **state,
                "respuesta": "Lo siento, no pude encontrar informaciÃ³n relevante en mis documentos financieros para responder a tu pregunta. Â¿PodrÃ­as reformularla o buscar algo diferente?",
                "fuente": "qdrant",
                "fragmentos": []
            }

        contexto = "\n\n".join(fragmentos)
        print(f"[ğŸ“š Nodo RAG] Contexto enviado al LLM (primeros 500 chars):\n'{contexto[:500]}...'")

        prompt_rag = PROMPT_RAG_DOCUMENTOS.format(
            contexto=contexto,
            pregunta_original=pregunta_original,
            pregunta_completa=pregunta_completa,
            fecha_actual=fecha_actual 
        )
        print(f"[ğŸ“š Nodo RAG] Prompt RAG enviado al LLM (primeros 500 chars):\n'{prompt_rag[:500]}...'")

        print("[ğŸ“š Nodo RAG] Invocando LLM para generar respuesta RAG...")
        llm_response_object = llm.invoke(prompt_rag)
        llm_response_raw = llm_response_object.content.strip()
        print(f"[ğŸ“š Nodo RAG] Respuesta RAW del LLM:\n'{llm_response_raw}'")

        respuesta_final_text = llm_response_raw
        respuesta_final_text = respuesta_final_text.replace(". ", ". \n").replace("- ", "â€¢ ")

        print(f"[ğŸ“š Nodo RAG] âœ… Respuesta final generada (primeros 500 chars):\n'{respuesta_final_text[:500]}...'")

        # --- NUEVO: Intentar extraer datos estructurados de la respuesta RAG para cache ---
        # Esto es un paso CRÃTICO. Si la respuesta RAG contiene un dato especÃ­fico
        # (ej. "Los beneficios de BBVA en 2023 fueron X"), necesitamos extraerlo aquÃ­.
        # Esto requerirÃ¡ un sub-LLM o regex inteligente para extraer el valor.
        # Por ahora, un ejemplo muy simplificado si buscas beneficios:
        
        empresa_preguntada = None
        # Primero, intenta identificar la empresa principal en la pregunta (si solo hay una)
        for empresa_ibex in [
            "bbva", "repsol", "iberdrola", "santander", "telefonica", "acciona",
            "acciona energia", "acerinox", "acs", "aena", "amadeus", "arcelormittal",
            "bankinter", "caixabank", "cellnex telecom", "enagas", "endesa",
            "ferrovial", "fluidra", "grifols", "iag", "inditex", "indra",
            "inm. colonial", "laboratorios farma (rovi)", "logista", "mapfre",
            "merlin properties", "naturgy", "puig", "ree", "sabadell", "sacyr",
            "solaria energia", "unicaja banco"
        ]:
            if empresa_ibex in pregunta_completa.lower():
                empresa_preguntada = empresa_ibex
                break

        if empresa_preguntada:
            # Ejemplo: Extraer beneficios si la pregunta es sobre "beneficios" y la respuesta RAG los contiene
            if "beneficios" in pregunta_completa.lower() or "ebitda" in pregunta_completa.lower():
                # Puedes usar otro LLM call o regex aquÃ­ para extraer el nÃºmero
                # Por simplicidad, un regex muy bÃ¡sico:
                match_beneficios = re.search(r"(\d[\d\.,]+)\s*(millones|miles de millones|â‚¬)", respuesta_final_text, re.IGNORECASE)
                if match_beneficios:
                    valor_str = match_beneficios.group(1).replace('.', '').replace(',', '.') # Convertir a formato numÃ©rico
                    unidad = match_beneficios.group(2).lower()
                    try:
                        valor_num = float(valor_str)
                        if "miles de millones" in unidad:
                            valor_num *= 1_000 # Convertir a millones si es el caso
                        elif "millones" in unidad:
                            valor_num *= 1 # Ya estÃ¡ en millones
                        
                        # Guardar en cache: {empresa: {metrica: {valor: X, unidad: Y, periodo: Z}}}
                        if empresa_preguntada not in datos_empresa_cache:
                            datos_empresa_cache[empresa_preguntada] = {}
                        
                        # Se necesita identificar quÃ© periodo de tiempo es (ej. 2023)
                        periodo_match = re.search(r"\b(20\d{2})\b", pregunta_completa) # Busca un aÃ±o
                        periodo = periodo_match.group(1) if periodo_match else "desconocido"

                        datos_empresa_cache[empresa_preguntada][f"beneficios_{periodo}"] = {
                            "valor": valor_num, 
                            "unidad": "millones â‚¬", 
                            "periodo": periodo
                        }
                        print(f"[ğŸ“š Nodo RAG] Datos estructurados extraÃ­dos y cacheado para {empresa_preguntada}: {datos_empresa_cache[empresa_preguntada][f'beneficios_{periodo}']}")
                    except ValueError:
                        print(f"[ğŸ“š Nodo RAG] No se pudo convertir el valor '{valor_str}' a nÃºmero.")

        return {
            **state,
            "respuesta": respuesta_final_text,
            "fuente": "qdrant",
            "fragmentos": fragmentos,
            "datos_empresa_cache": datos_empresa_cache # Actualizar el cache en el estado
        }

    except Exception as general_e:
        print(f"âŒ Error CRÃTICO y general en el nodo Qdrant: {general_e}")
        return {
            **state,
            "respuesta": f"Lo siento mucho, hubo un problema tÃ©cnico inesperado al procesar tu solicitud de documentos financieros. Detalles: {general_e}. Por favor, intÃ©ntalo de nuevo o formula la pregunta de otra manera.",
            "fuente": "error_qdrant",
            "fragmentos": [],
            "datos_empresa_cache": datos_empresa_cache # Asegurar que el cache se pase incluso en error
        }

# ---------------------------------------------------------
# 8. Nodo: Consulta API financiera - Â¡ACTUALIZADO!
# ---------------------------------------------------------

def consultar_api_financiera(state: ChatbotState) -> ChatbotState:
    pregunta_original = state["input"]
    pregunta_para_api_extraccion = state["pregunta_completa"]
    fecha_actual = state["fecha_actual"] 
    print(f"[ğŸŒ Nodo API] Pregunta original para extracciÃ³n: {pregunta_original}")
    print(f"[ğŸŒ Nodo API] Pregunta completa para extracciÃ³n: {pregunta_para_api_extraccion}")
    print(f"[ğŸŒ Nodo API] Fecha actual (del estado): {fecha_actual}")

    # Inicializar o recuperar datos_empresa_cache
    datos_empresa_cache = state.get("datos_empresa_cache", {})

    extraction_prompt = PROMPT_API_EXTRAER.format(
        pregunta_original=pregunta_original,
        pregunta_completa=pregunta_para_api_extraccion,
        fecha_actual=fecha_actual 
    )
    
    print(f"[ğŸŒ Nodo API] Prompt de extracciÃ³n:\n{extraction_prompt}")
    
    response = llm.invoke(extraction_prompt)
    llm_response_content = response.content.strip()
    
    print(f"[ğŸŒ Nodo API] Respuesta LLM para extracciÃ³n CRUDA:\n'{llm_response_content}'")
    
    empresa_normalizada = None
    fecha_inicio = None
    fecha_fin = None
    
    try:
        data = extract_json(llm_response_content)
        print(f"[ğŸŒ Nodo API] Datos extraÃ­dos del LLM:\n{data}")

        empresa = data.get("empresa")
        if not empresa:
            print("âš ï¸ No se pudo extraer la empresa del JSON")
        empresa_normalizada = empresa.strip().lower() if empresa else None  
        print(f"[ğŸŒ Nodo API] Empresa normalizada: {empresa_normalizada}")
        
        fecha_inicio = data.get("fecha_inicio")
        fecha_fin = data.get("fecha_fin")
        fecha_inicio, fecha_fin = normalizar_fechas_relativas(fecha_inicio, fecha_fin)
        print(f"[ğŸŒ Nodo API] Fechas normalizadas: {fecha_inicio}, {fecha_fin}")

    except Exception as e:
        print(f"âš ï¸ Error extrayendo parÃ¡metros para API: {e}")
        # No se retorna, se continÃºa para dar un mensaje de error mÃ¡s especÃ­fico si faltan parÃ¡metros.


    if not all([empresa_normalizada, fecha_inicio, fecha_fin]):
        print(f"âš ï¸ Faltan parÃ¡metros clave: empresa={empresa_normalizada}, fecha_inicio={fecha_inicio}, fecha_fin={fecha_fin}")
        return {
            **state,
            "respuesta": "âŒ Faltan parÃ¡metros clave: empresa, fecha de inicio o fin. Por favor, sÃ© mÃ¡s especÃ­fico.",
            "fuente": "api",
            "datos_empresa_cache": datos_empresa_cache # Asegurar que el cache se pase incluso en error
        }

    resultado = construir_respuesta_yfinance(empresa_normalizada, fecha_inicio, fecha_fin)
    print(f"[ğŸŒ Nodo API] Resultado de la API financiera:\n{resultado.get('respuesta', 'N/A')}")

    # --- NUEVO: Guardar el precio medio en el cache ---
    precio_medio = resultado.get("precio_medio") # Asume que construir_respuesta_yfinance devuelve 'precio_medio'
    if precio_medio is not None and empresa_normalizada:
        if empresa_normalizada not in datos_empresa_cache:
            datos_empresa_cache[empresa_normalizada] = {}
        
        # Usar la fecha_fin como identificador para este punto de datos
        datos_empresa_cache[empresa_normalizada][f"precio_cierre_{fecha_fin}"] = {
            "valor": precio_medio, 
            "unidad": "â‚¬", 
            "periodo": fecha_fin # O el rango de fechas
        }
        print(f"[ğŸŒ Nodo API] Precio medio cacheado para {empresa_normalizada}: {precio_medio}")


    return {
        **state,
        "respuesta": resultado.get('respuesta', "No se pudo obtener el precio."),
        "fuente": "api",
        "empresa": empresa_normalizada,
        "fecha_inicio": fecha_inicio,
        "fecha_fin": fecha_fin,
        "datos_empresa_cache": datos_empresa_cache # Actualizar el cache en el estado
    }

# ---------------------------------------------------------
# 9. Nodo: Actualizar Historial Completo
# ---------------------------------------------------------

def actualizar_historial_final(state: ChatbotState) -> ChatbotState:
    historial_completo_previo = state.get("historial_completo", [])
    
    nueva_entrada = {
        "pregunta_usuario": state["input"],
        "pregunta_procesada": state.get("pregunta_completa", state["input"]),
        "respuesta_asistente": state.get("respuesta", "No se pudo generar una respuesta."),
        "fuente": state.get("fuente", "desconocida"),
        "timestamp": datetime.now().isoformat(),
        # TambiÃ©n guardar los datos estructurados que se procesaron en esta iteraciÃ³n
        "datos_generados": state.get("datos_recopilados", {}) 
    }
    
    historial_completo_actualizado = historial_completo_previo + [nueva_entrada]

    historial_completo_actualizado = historial_completo_actualizado[-10:] 

    print(f"[ğŸ”„ HISTORIAL] Historial completo actualizado. Total entradas: {len(historial_completo_actualizado)}")
    print(f"[ğŸ”„ HISTORIAL] Ãšltima entrada: {nueva_entrada}")

    return {
        **state,
        "historial_completo": historial_completo_actualizado
    }


# ---------------------------------------------------------
# 10. ConstrucciÃ³n del grafo 
# ---------------------------------------------------------

def build_graph():
    graph = StateGraph(ChatbotState)
    graph.add_node("clasificar", RunnableLambda(clasificar_intencion))
    graph.add_node("series_temporales", RunnableLambda(analizar_series_temporales))
    graph.add_node("consulta_qdrant", RunnableLambda(consulta_qdrant))
    graph.add_node("consulta_api", RunnableLambda(consultar_api_financiera))
    graph.add_node("actualizar_historial", RunnableLambda(actualizar_historial_final)) 

    graph.set_entry_point("clasificar")

    graph.add_conditional_edges("clasificar", seleccionar_fuente, {
        "series_temporales": "series_temporales",
        "documentos_financieros": "consulta_qdrant",
        "consulta_api": "consulta_api",
        # Eliminada la rama "comparacion_financiera"
    })

    graph.add_edge("series_temporales", "actualizar_historial")
    graph.add_edge("consulta_qdrant", "actualizar_historial")
    graph.add_edge("consulta_api", "actualizar_historial")
    # Eliminada la conexiÃ³n desde "generar_comparacion"
    
    graph.add_edge("actualizar_historial", END)

    return graph.compile()

graph = build_graph()

# ---------------------------------------------------------
# 11. FunciÃ³n principal para interactuar con el chatbot
# ---------------------------------------------------------

def chatbot_response(user_input: str, current_state: Optional[ChatbotState] = None) -> ChatbotState:
    if current_state is None:
        current_state = ChatbotState(
            input=user_input,
            historial_preguntas=[],
            historial_completo=[],
            fecha_actual=datetime.now().strftime("%Y-%m-%d"),
            datos_empresa_cache={} # Inicializa el cache vacÃ­o
        )
    else:
        current_state["input"] = user_input
        current_state["fecha_actual"] = datetime.now().strftime("%Y-%m-%d")

    final_state = graph.invoke(current_state) 
    return final_state

if __name__ == "__main__":
    print("ğŸ” Chatbot Financiero IBEX 35 - Modo Interactivo")
    print("Escribe tus preguntas una por una. Escribe 'salir' para terminar.\n")

    current_chat_state: Optional[ChatbotState] = None

    # Test cases as requested
    test_questions = [
        "Â¿CuÃ¡l fue el precio de BBVA ayer?",
        "Â¿Y el de Bankinter?",
        "Â¿QuÃ© beneficio neto atribuido obtuvo Iberdrola en 2024 y cÃ³mo evolucionÃ³ respecto al aÃ±o anterior?",
        "Â¿CuÃ¡les son los tres ejes del nuevo plan estratÃ©gico de Bankinter para el periodo 2024â€“2026?"

    ]

    for i, user_question in enumerate(test_questions):
        print(f"\n\n--- PREGUNTA DE PRUEBA {i+1}: {user_question} ---")
        if current_chat_state is None:
            current_chat_state = ChatbotState(
                input=user_question,
                historial_preguntas=[],
                historial_completo=[],
                fecha_actual=datetime.now().strftime("%Y-%m-%d"),
                datos_empresa_cache={}
            )
        else:
            current_chat_state["input"] = user_question
            current_chat_state["fecha_actual"] = datetime.now().strftime("%Y-%m-%d")

        try:
            result_state = graph.invoke(current_chat_state)

            print("\nâœ… Respuesta generada:")
            print(result_state.get("respuesta", "âŒ No se generÃ³ ninguna respuesta."))

            print("\nğŸ“Š Detalles del estado:")
            print(f"- ClasificaciÃ³n: {result_state.get('tipo_pregunta', 'No detectada')}")
            print(f"- Empresa: {result_state.get('empresa', 'No detectada')}")
            print(f"- Fuente: {result_state.get('fuente', 'No disponible')}")
            print(f"- Fechas: {result_state.get('fecha_inicio')} -> {result_state.get('fecha_fin')}")
            print(f"- Pregunta completa: {result_state.get('pregunta_completa', '')}")
            print(f"- Historial: {result_state.get('historial_preguntas', [])}")
            print(f"- Cache de Datos (Ãºltimo estado): {json.dumps(result_state.get('datos_empresa_cache', {}), indent=2)}")

            # Update the state for the next question
            current_chat_state = result_state

        except Exception as e:
            print(f"\nâŒ Error en el procesamiento del chatbot: {e}")
            print("ğŸ” Por favor, intenta con otra pregunta.\n")
    
    # You can continue with interactive mode after the test questions if you want
    print("\n--- FIN DE PRUEBAS AUTOMÃTICAS ---")
    print("Puedes seguir preguntando en modo interactivo si lo deseas. Escribe 'salir' para terminar.")
    
    while True:
        user_question = input("\nğŸ§  Tu pregunta: ").strip()
        if user_question.lower() in {"salir", "exit", "quit"}:
            print("ğŸ‘‹ Terminando la sesiÃ³n. Â¡Hasta la prÃ³xima!")
            break

        if current_chat_state is None:
            current_chat_state = ChatbotState(
                input=user_question,
                historial_preguntas=[],
                historial_completo=[],
                fecha_actual=datetime.now().strftime("%Y-%m-%d"),
                datos_empresa_cache={}
            )
        else:
            current_chat_state["input"] = user_question
            current_chat_state["fecha_actual"] = datetime.now().strftime("%Y-%m-%d")

        try:
            result_state = graph.invoke(current_chat_state)

            print("\nâœ… Respuesta generada:")
            print(result_state.get("respuesta", "âŒ No se generÃ³ ninguna respuesta."))

            print("\nğŸ“Š Detalles del estado:")
            print(f"- ClasificaciÃ³n: {result_state.get('tipo_pregunta', 'No detectada')}")
            print(f"- Empresa: {result_state.get('empresa', 'No detectada')}")
            print(f"- Fuente: {result_state.get('fuente', 'No disponible')}")
            print(f"- Fechas: {result_state.get('fecha_inicio')} -> {result_state.get('fecha_fin')}")
            print(f"- Pregunta completa: {result_state.get('pregunta_completa', '')}")
            print(f"- Historial: {result_state.get('historial_preguntas', [])}")
            print(f"- Cache de Datos (Ãºltimo estado): {json.dumps(result_state.get('datos_empresa_cache', {}), indent=2)}")


            current_chat_state = result_state

        except Exception as e:
            print(f"\nâŒ Error en el procesamiento del chatbot: {e}")
            print("ğŸ” Por favor, intenta con otra pregunta.\n")